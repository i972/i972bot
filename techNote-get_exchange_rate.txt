#
# get_exchange_rate()
# 환율 정보를 네이버 에서 스크래핑 하는 함수 입니다. 

# 추가 정보
https://oo.ai/s/kE7MZ4extboSeLsoFc0h


이 코드는 네이버 금융에서 특정 국가의 환율 정보를 웹 스크래핑하는 간단한 예제입니다. 웹 스크래핑 초보자의 관점에서 각 부분을 상세히 설명해 드릴게요.

1. 웹 스크래핑이란?
    우선, **웹 스크래핑(Web Scraping)**이 무엇인지부터 알아야 합니다. 웹 스크래핑은 웹사이트에 있는 정보를 자동으로 추출하는 기술입니다. 우리가 웹 브라우저로 웹사이트를 방문하여 정보를 눈으로 보고 수동으로 복사하는 대신, 컴퓨터 프로그램이 웹사이트의 내용을 읽어서 필요한 정보만 쏙쏙 뽑아내는 것이라고 생각하면 됩니다. 이 코드는 파이썬이라는 프로그래밍 언어를 사용해서 이 작업을 수행합니다.

2. 코드의 전체적인 흐름
    이 코드는 다음과 같은 흐름으로 작동합니다:

    필요한 도구 불러오기: 웹 스크래핑을 위해 필요한 라이브러리(도구)들을 불러옵니다.

    환율 정보 가져오는 함수 정의: 특정 통화 코드(예: USD, HKD)를 입력받아 해당 통화의 상세 환율 정보를 가져와 출력하는 함수를 만듭니다.

    함수 실행: 정의된 함수를 호출하여 실제 환율 정보를 가져와 화면에 출력합니다.

    이제 각 부분을 자세히 살펴보겠습니다.

3. 코드 상세 설명
    3.1. 필요한 도구 불러오기
        Python
        ￼
            import requests
            from bs4 import BeautifulSoup

        import requests: requests는 파이썬에서 웹사이트에 HTTP 요청을 보내는 데 사용되는 라이브러리입니다. 쉽게 말해, 우리가 웹 브라우저 주소창에 URL을 입력하고 엔터를 치는 것처럼, requests는 파이썬 코드에서 웹사이트에 접속해달라고 요청하는 역할을 합니다. 이 요청을 통해 웹사이트의 HTML 내용(소스 코드)을 받아올 수 있습니다.

        from bs4 import BeautifulSoup: BeautifulSoup은 HTML이나 XML 파일에서 우리가 원하는 데이터를 쉽게 찾아낼 수 있도록 도와주는 라이브러리입니다. requests로 웹사이트의 HTML 내용을 가져왔다면, 그 HTML은 복잡한 텍스트 덩어리일 뿐입니다. BeautifulSoup은 이 복잡한 HTML을 파이썬에서 다루기 쉬운 형태로 변환해주고, 특정 태그나 클래스 이름 등을 이용해서 원하는 정보를 '예쁘게' 찾아낼 수 있게 해줍니다.

    3.2. get_exchange_rate 함수 정의
        이 함수는 currency_code (통화 코드, 예: 'USD')를 입력받아 해당 통화의 상세 환율 정보를 가져옵니다.

        Python
        ￼
            def get_exchange_rate(currency_code):
        
        def get_exchange_rate(currency_code):: def는 "함수를 정의하겠다"는 의미입니다. get_exchange_rate라는 이름의 함수를 만들고, 이 함수를 호출할 때 currency_code라는 값을 넘겨줄 것이라는 의미입니다.

        3.2.1. 웹사이트 접속 및 HTML 가져오기
            Python
            ￼
                url = 'https://finance.naver.com/marketindex/exchangeDetail.naver?marketindexCd=FX_' + currency_code + 'KRW'
                response = requests.get(url)
                html_content = response.text
                soup = BeautifulSoup(html_content, 'html.parser')
            
            url = '...' + currency_code + 'KRW': 스크래핑할 웹사이트의 URL을 만듭니다. 여기서 중요한 것은 currency_code 변수를 사용해서 URL을 동적으로 만든다는 점입니다.

            예를 들어, currency_code가 'USD'이면 URL은 https://finance.naver.com/marketindex/exchangeDetail.naver?marketindexCd=FX_USDKRW가 됩니다.

            이 URL은 네이버 금융에서 각 통화의 상세 환율 정보를 보여주는 페이지입니다.

            response = requests.get(url): 위에서 만든 url로 웹사이트에 접속(HTTP GET 요청)합니다. 이 요청의 결과는 response라는 변수에 저장됩니다. response 객체 안에는 웹사이트가 돌려준 정보(HTML 내용, 상태 코드 등)가 들어있습니다.

            html_content = response.text: response 객체에서 웹사이트의 HTML 내용을 텍스트 형태로 추출하여 html_content 변수에 저장합니다. 이 변수에는 우리가 웹 브라우저에서 '페이지 소스 보기'를 했을 때 보이는 그 HTML 코드가 통째로 들어있습니다.

            soup = BeautifulSoup(html_content, 'html.parser'): 드디어 BeautifulSoup이 등장합니다! html_content에 담긴 HTML 텍스트를 BeautifulSoup이 이해하기 쉬운 형태로 변환합니다. html.parser는 HTML을 분석하는 데 사용할 파서(분석기)를 지정하는 것입니다. 이렇게 soup 객체가 만들어지면, 우리는 이 soup 객체를 통해 HTML 내용에서 원하는 정보를 쉽게 찾아낼 수 있습니다.

        3.2.2. 원하는 정보 찾기 (HTML 요소 선택)
            이제 soup 객체를 이용해서 웹 페이지에서 필요한 정보를 추출합니다. 웹 스크래핑에서 가장 중요한 부분은 웹 페이지의 HTML 구조를 이해하고, 원하는 정보가 어떤 HTML 태그, 클래스, ID 안에 있는지 파악하는 것입니다. 이를 위해 웹 브라우저의 '개발자 도구'를 사용하는 것이 일반적입니다. (F12 키를 눌러서 볼 수 있어요!)

            국가명 (country) 추출:

            Python
            ￼
                country = soup.find('h2').get_text().replace(' ', '')
            
            soup.find('h2'): soup 객체에서 첫 번째로 발견되는 <h2> 태그를 찾습니다. <h2> 태그는 보통 제목을 나타내며, 이 페이지에서는 국가명(예: "미국 USD")이 들어있습니다.

            .get_text(): 찾아낸 <h2> 태그 안에 있는 텍스트 내용만 가져옵니다. HTML 태그 자체는 제외됩니다.

            .replace(' ', ''): 텍스트 내용 중에 공백이 있다면 모두 제거합니다. (예: "미국 USD" -> "미국USD")

            실시간 환율 (rate_info) 추출:

            Python
            ￼
                rate_info = soup.find('p', class_='no_today').get_text().replace('\n', '')
            
            soup.find('p', class_='no_today'): <p> 태그 중에서 class 속성이 'no_today'인 첫 번째 요소를 찾습니다. 이 클래스는 네이버 금융 페이지에서 현재 환율 값을 표시하는 데 사용됩니다.

            .get_text(): 해당 <p> 태그 안의 텍스트 내용을 가져옵니다.

            .replace('\n', ''): 텍스트 내용 중 줄바꿈 문자(\n)가 있다면 모두 제거합니다.

            등락 기호 (change_icon) 추출 및 결정:

            Python
            ￼
                change_icon = soup.find('span', class_='ico')

                if change_icon:
                    if 'up' in change_icon['class']:
                        change_sign = '▲'
                    elif 'down' in change_icon['class']:
                        change_sign = '▼'
                    elif 'same' in change_icon['class']:
                        change_sign = ''
            
            soup.find('span', class_='ico'): <span> 태그 중에서 class 속성이 'ico'인 첫 번째 요소를 찾습니다. 이 <span> 태그는 환율 변동 방향(상승, 하락, 동일)을 나타내는 아이콘(▲, ▼, -)을 포함하고 있습니다.

            if change_icon:: change_icon이 존재하는지 확인합니다. 만약 해당 <span> 태그가 페이지에 없으면 None이 반환되므로 오류를 방지하기 위해 확인합니다.

            if 'up' in change_icon['class']:: change_icon 요소의 class 속성 목록(change_icon['class']는 리스트 형태)에 'up'이라는 클래스가 포함되어 있는지 확인합니다. 만약 포함되어 있다면 환율이 상승했으므로 change_sign을 '▲'로 설정합니다.

            elif 'down' in change_icon['class']:: up이 아니고 'down' 클래스가 있다면 환율이 하락했으므로 '▼'로 설정합니다.

            elif 'same' in change_icon['class']:: up, down이 아니고 'same' 클래스가 있다면 환율 변동이 없으므로 change_sign을 빈 문자열로 설정합니다.

            전일대비 정보 (exday_info) 추출:

            Python
            ￼
                exday_info = soup.find('p', class_='no_exday').get_text().replace('\n', '').replace('전일대비', '')
            
            soup.find('p', class_='no_exday'): <p> 태그 중에서 class 속성이 'no_exday'인 첫 번째 요소를 찾습니다. 이 클래스는 전일대비 변동 폭을 나타냅니다.

            .get_text(): 해당 <p> 태그 안의 텍스트 내용을 가져옵니다.

            .replace('\n', ''): 줄바꿈 문자 제거.

            .replace('전일대비', ''): 텍스트 내용 중에 "전일대비"라는 문자열이 있다면 제거합니다. 이렇게 하면 숫자 값만 남게 됩니다.

        3.2.3. 결과 출력
            Python
            ￼
                print(country, currency_code, "실시간 환율", rate_info, '｜ 전일대비', change_sign, exday_info)
            
            추출된 모든 정보를 보기 좋게 조합하여 화면에 출력합니다. 각 정보는 쉼표(,)로 구분되어 출력되며, 공백으로 자동 분리됩니다. '｜' 문자는 시각적으로 정보를 구분하기 위해 추가된 것입니다.

4. 함수 실행
    Python
    ￼
        # USD, HKD, THB 환율 확인하기
        get_exchange_rate('USD')
        get_exchange_rate('HKD')
        get_exchange_rate('THB')
    
    get_exchange_rate 함수를 각각 'USD', 'HKD', 'THB' 통화 코드를 인자로 전달하여 호출합니다. 이렇게 하면 각 통화에 대한 환율 정보가 순서대로 출력됩니다.

5. 요약 및 추가 팁
    이 코드는 다음과 같은 과정을 거쳐 웹 스크래핑을 수행합니다.

    URL 결정: 어떤 웹 페이지에서 정보를 가져올지 URL을 정합니다.

    HTML 가져오기: requests 라이브러리를 사용하여 해당 URL의 HTML 내용을 가져옵니다.

    HTML 파싱: BeautifulSoup 라이브러리를 사용하여 가져온 HTML을 파이썬이 다루기 쉬운 객체로 변환합니다.

    정보 추출: BeautifulSoup의 find() 또는 select()와 같은 메서드를 사용하여 HTML 구조 내에서 원하는 정보(텍스트, 속성 등)를 찾아 추출합니다. 이때 가장 중요한 것이 웹 브라우저의 **개발자 도구(F12)**를 사용하여 HTML 구조를 직접 분석하는 것입니다.

    정보 가공 및 출력: 추출된 정보를 필요한 형태로 가공하고 화면에 출력합니다.

초보자를 위한 추가 팁:

    개발자 도구 활용: 웹 스크래핑을 할 때는 웹 브라우저의 개발자 도구를 능숙하게 사용하는 것이 필수입니다. F12를 눌러서 HTML 요소를 클릭하면 해당 요소의 코드 위치를 바로 확인할 수 있습니다.

    HTML 구조 이해: <div>, <p>, <span>, <a>, <table> 등 기본적인 HTML 태그와 class, id와 같은 속성의 의미를 이해하면 스크래핑이 훨씬 쉬워집니다.

    오류 처리: 웹사이트의 구조가 변경되거나 네트워크 오류가 발생할 수 있으므로, 실제 서비스에 적용할 때는 try-except 구문을 사용하여 예외 처리를 추가하는 것이 좋습니다. (이 코드에서는 requests.exceptions.RequestException과 같은 기본적인 네트워크 오류는 다루지 않고 있습니다.)

    웹사이트 정책 확인: 모든 웹사이트가 스크래핑을 허용하는 것은 아닙니다. robots.txt 파일을 확인하거나 웹사이트의 이용 약관을 읽어 웹 스크래핑이 허용되는지 미리 확인하는 것이 중요합니다. 너무 잦은 요청은 IP 차단으로 이어질 수 있으니 주의해야 합니다.